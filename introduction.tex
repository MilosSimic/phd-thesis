%!TEX root =  main.tex
\pagestyle{fancy}
\fancyhf{}
\fancyhead[RE,LO]{\leftmark}
\fancyfoot[CE,CO]{\thepage}
\chapter{Introduction}\label{chapter:Intro}
%
Various software systems have changed the way people communicate, share information, learn, and run businesses. The interconnected computing devices have numerous positive applications in everyday life. In the past decade or so, the volumes of data that is collected, stored, and computed have grown dramatically~\cite{ChiangZ16}. 

New age applications that might include augmented reality, massive online gaming, face recognition, autonomous drones and vehicles, or the Internet of Things (IoT) produce enormous amounts of different kinds of data. 

Such workloads require that latency is below a few tens of milliseconds~\cite{ChiangZ16}, or even less. These requirements fall just right outside of what a standard centralized model like cloud computing (CC), for example, could offer~\cite{ChiangZ16}. Even the smallest problems can contribute to largely unplanned downtime of applications and services people and other services may depend on. A most recent example is yet another outage that happened to the Amazon Web Services (AWS), and as a result, a large amount of internet becomes unavailable~\cite{GunawiHSLSAE16}.

This thesis aims to provide formal models based on which we can model and implement distributed systems (DS) for organizing cloud-like geo-distributed environments for users or CC providers. We can look at the whole system as a micro clouds ($\upmu$Cs) or pre-processing layer. The responsibility of such a system is sending only necessary and data to the cloud. This strategy reduces cost for users and ensures the availability of CC services. Such a system could lead to lowering the downtime of critical services. Here w can give a formal definitino of geo-distributed environments like:

\begin{definition}
	geo-distribution represent organizing processing and storage resources in proximity to some large populations, where $\upmu$Cs are formed dynamically, serving users requests \textbf{locally first}. 
\end{definition}

It starts by describing the general problem area that our work addresses in Section~\ref{sec:problem_area}. Section~\ref{sec:problem_statement}, specifies the exact problem that our work addresses, and Section~\ref{sec:research_hyphotesis_and_golas} describes our hypothesis and research goals. Section~\ref{sec:structure_of_thesis} presents the structure of the thesis.
%
%
%
\section{Problem area}\label{sec:problem_area}
%
To lower the administration cost, cloud providers create an effective economy of scale~\cite{BariBEGPRZZ13} by housing data-centers (DCs) with huge capacities. However, such a model does not come without the cost. When such a  system grows to its physical limits, a centralized model brings more harm than good~\cite{GunawiHSLSAE16, LopezMEDHIBFR15}. 

Despite all the benefits that centralization can provide, it is inevitable for the CC services to suffer from serious problems~\cite{KarimIWGSYO16}. Over time, and due to the high bandwidth and latency, these services face degradation that we cannot overlook. This serious services degradation can have an enormous consequence on the human business and potentially lives as well~\cite{El-SayedSPPGML18}. 

To avoid large investments~\cite{MonsalveCC18}, like creating and maintaining their own DCs, organizations use cloud services created by others~\cite{Satyanarayanan17}. They consume resources and pay for their usage time. This model is known as -- pay as you go model.

CC requires data transfer to the DCs from data sources. This operation is problematic because it creates a high latency in the system~\cite{HossainRH18}. We can observe some examples like data collection from planes and autonomous cars. Boeing 787s per single flight generates half a terabyte of data, while a self-driving car generates two petabytes of data per single drive. On the other hand, bandwidth is not large enough to support such requirements~\cite{CaoZS18}. 

Data transfer is not the only problem CC is facing. Some applications require real-time processing for proper decision-making~\cite{CaoZS18}. For example, self-driving cars, delivery drones, or power balancing in electric grids. Such applications might face serious issues if a cloud service becomes unavailable due to whatever reason~\cite{GunawiHSLSAE16}.

Over the years, research led to new computing areas and models in which computing and storage utilities are in proximity to data sources~\cite{Satyanarayanan17}. To overcome cloud latency issues centralized CC model is enhanced with some new ideas~\cite{NingLSY20}.
%
%
\section{Motivation and Problem Statement}\label{sec:problem_statement}
%
In their work~\cite{GreenbergHMP09} Greenberg et al. point out that micro data-centers ($\upmu$DCs) are used primarily as nodes in content distribution networks and other \say{embarrassingly distributed} applications.

One size rarely suits all needs, so the CC should not be our final computing shift. Various models presented in~\ref{sec:mobile_computing} show a promising possibility of how computing could be done closer to the data sources, to lower the latency for its clients by contacting the cloud only when needed, while the heavy computation could remain in the cloud, because of more available resources. Send to the cloud only information that is crucial for other services or applications~\cite{inproceedingsSimic1}. Not ingest everything as the standard cloud model proposes.

A zonally-based organization of servers combined with $\upmu$DCs shows a great possibility for building $\upmu$Cs and EC as a service. To achieve such a behavior, a few more abstractions and layers are needed, to make the whole system more available, resilient, and with less latency. By their nature, EC originates from P2P systems~\cite{LopezMEDHIBFR15} as suggested by L{\'{o}}pez et al., but expands it into new directions and blends it with the CC. 

This is very interesting, because there is much research and knowledge available for P2P systems that could be used for inspiration. One extension of the P2P system leads to geo-distributed deployments, and going from node to node is a time-consuming process. Satyanarayanan et al. stated that infrastructure deployment will not happen until the whole process is relatively easy~\cite{SatyanarayananBCD09}. 

Assuming that we have a well-defined system, and so that infrastructure can be easily deployed and operated with, we have a system that could be offered like any other resource in the CC -- \emph{as a service}. Such a system or service could be offered to various types of users, from researchers to developers to create new types of applications. A well-defined system that is easy to operate with, will be able to move resources from one place to another with no problem. Some cloud providers, though, might choose to integrate the system into their existing CC platform to reduce the load or avoid bottlenecks and single points of failure~\cite{JararwehDAAAB16}.

The idea of small-scale servers introduced by edge computing (EC), with heterogeneous, compute, storage, and network resources, raise interesting research ideas and it is the main motivation for this thesis. Taking advantage of resources organized locally as $\upmu$Cs, community clouds, or edge clouds~\cite{RydenOCW14, SimicAccess} suggested by Ryden et al., to help power-hungry servers reduce traffic~\cite{HirschMZ18}; contactacting the cloud only when needed~\cite{inproceedingsSimic1}; sending to the cloud only information that is crucial for other services or applications; not ingesting everything as the standard CC model proposes.

To achieve such behavior, dynamic resource management, and device management is essential. At any given time, available resources, configuration, and utilization of the system must be known~\cite{GubbiBMP13, WangZZWYW17}. Traditional DCs is a well organized and connected system, built upon years of experience. On the other hand, these $\upmu$DCs consist of various devices, including ones presented in~\ref{sec:mobile_computing} that are not~\cite{JiangCGZW19}. This idea brings us to the problem this thesis addresses.

Currently, existing EC and $\upmu$DCs models lack dynamic, well defined geo-organization structure, native applications model, and a clear separation of concerns model. As such they cannot be offered as a service to the users, and it is hard to form $\upmu$Cs on them. Usually, these systems exist independently from one another, scattered without any communication between them. Providers who build and maintain these systems, usually lock users in their ecosystem, frequently integrate tightly with their cloud services, giving users small or even no other options. Nearby EC nodes could be organized locally, making the whole system more available and reliable, but at the same time extending resources beyond the single node or group of nodes, maintaining good performance to build servers and clusters~\cite{ArocaG12}.

This cloud extension strengthens our understanding of not just DS but also CC as a system and field of research. With EC native applications model, separation of concerns well defined, and a unified node organization strategy, we are moving towards the idea of EC as a service and $\upmu$Cs~\cite{SimicAccess}. 

Based on this, the problem this thesis is trying to solve is defined by the three research questions:

\begin{enumerate}[start=1,label={(\bfseries \arabic*)}]\label{questions}
	\item \textit{Can geo-distributed EC nodes be organized in a similar  way to the cloud, but adopted for the different environment, with clear separation of concerns and familiar applications model for users forming $\upmu$C a model?}
	\item \textit{Can these organized nodes ($\upmu$Cs) be offered as a service based on the cloud pay as you go model, to the developers and researchers so that they can develop new human-centered applications?}
	\item \textit{Can a model be made in such a way that is formally correct, easy to extend, understand and reason about?}
\end{enumerate}

\noindent
This $\upmu$C model makes both system and applications more available and reliable, while resources are extended further beyond the single node or even $\upmu$DCs. In his work~\cite{SatyanarayananK19} Satyanarayanan et al. shows that $\upmu$DCs can serve as firewalls, while users get a unique ability to dynamically and selectively control their information that will be uploaded to the cloud.  Simi\' c et al., in~\cite{inproceedingsSimic1} uses a similar idea as a pre-processing tier for the cloud. Years after its inception, EC is no longer just an idea~\cite{SatyanarayananK19} but a must-have tool for novel applications to come. 
%
%
\section{Research Hypotheses, and Goals}\label{sec:research_hyphotesis_and_golas}
%
Based on research questions presented on page~\pageref{questions}, and motivation presented in section~\ref{sec:problem_statement}, the hypothesis around which this thesis is based, is derived. They can be summarized as follows:

\begin{enumerate}[start=1,label={(\bfseries \arabic*)}]
	\item \textbf{Hypothesis:} \textit{It is possible to organize EC nodes in a standard way based on cloud architecture, adapted for EC geo-distributed environment -- \textbf{$\upmu$Cs}. Giving users the unique ability to organize nodes, descriptively, in the best possible way to serve the population nearby.}
	\item \textbf{Hypothesis:} \textit{It is possible to offer a newly formed $\upmu$C model to researchers and developers as a service based on the cloud pay as you go model to create new human-centered applications, but sustain the ability to rearrange resources as needed.}
	\item \textbf{Hypothesis:} \textit{It is possible to form a clear separation of concerns for the future $\upmu$C model (EC as a service model) and establish a well-organized system with an intuitive role for every part.} 
	\item \textbf{Hypothesis:} \textit{It is possible to present a unified model that will be able to support heterogeneous small-scale servers (EC nodes). This unified model will rely on a set of technical requirements that nodes must fulfill to join the system.}
	\item \textbf{Hypothesis:} \textit{It is possible to present a clear and familiar application model so that users can use the full potential of newly created infrastructure but familiarly and intuitively.}
\end{enumerate}

\noindent
From the previously defined hypotheses, the primary goals of this thesis can be derived, where the expected results include:

\begin{enumerate}[start=1,label={(\bfseries \arabic*)}]
	\item \textit{The construction of a model with a clear separation of concerns for the model influenced by cloud organization, with adaptations for a different environment, and with a model for EC applications utilizing these adaptations. This addresses the first research question and is the topic of Chapter~\ref{chapter:Micro_clouds}.}
	\item \textit{The constructed model is more available, resilient with less latency, and as such it can be offered to the general public as a service like any other service in the cloud. This addresses the second research question and is the topic of Chapter~\ref{chapter:Micro_clouds}.}
	\item \textit{The constructed model is described formally well, using solid mathematical theory, but also easy to extend both formally and technically, easy to understand and reason about. This addresses the third research question and is the topic of Chapter~\ref{chapter:Micro_clouds}.}
\end{enumerate}
%
%
\section{Structure of the thesis}\label{sec:structure_of_thesis}
%
Throughout this introductory Chapter~\ref{chapter:Intro}, the motivation for this work is defined, with problems that this thesis addresses. The rest of the thesis is outlined here.

Chapter~\ref{chapter:Field_overview} presents the necessary background details, informations, and areas for understanding and supporting the rest of the thesis.

Chapter~\ref{chapter:Review} presents the literature review, where different aspects of existing systems and methods important for the thesis are examined. Existing organizational abilities for nodes in both industry and academia frameworks are analyzed, as well as solutions to address the first research question. Platform models from industry and academia tools and frameworks are examined further to address the second research question. And last but not least, current strategies to offload tasks from the cloud are examined. All three parts address the third research question.

Chapter~\ref{chapter:Micro_clouds} details the model, how it is related to other research and where it connects to other existing models and solutions. The solution, as well as protocols required for such a system to be implemented formally are further described. 

Chapter~\ref{chapter:Implementation} presents implementation details of a framework implemented to test defined hypotheses, and answer research questions. The framework is implemented based on the protocols formally described in chapter~\ref{chapter:Micro_clouds}. This chapter also shows results after conducting experiments.

Chapter~\ref{chapter:Model usability} presents usability of the proposed model, and possible applications that could benefit from such a system. There are also examples of how existing infrastructure could be used, as well as familiar application model for developers.

Chapter~\ref{chapter:Conclusion} is the final chapter, and it concludes the work of this thesis. It summarizing the contributions of this thesis, presenting the limitations of the proposed model, and outlines the opportunities and directions for further research and development in this area.
%
%