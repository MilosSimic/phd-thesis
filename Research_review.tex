%!TEX root =  main.tex
\chapter{Research review}\label{chapter:Review}
%
In this chapter, we present the the results of the research reviews addressing issues and limits of CC discussed earlier are presented -- both academia, and the industry researching and developing viable solutions to help cloud in the future. 

Few directions are feasible: \textbf{(1)} focusing on adapting existing solutions to fit EC model, \textbf{(2)} experiment and develop new ideas and solutions to maybe fit more the nature of EC, and \textbf{(3)} try to combine both ideas to cover more research area.

Existing nodes organizational abilities are reviewed in section~\ref{sec:nodes_organization}. Section~\ref{sec:nodes_organization} reviews platform models from both industry and academia. Section~\ref{sec:task_offloading} reviews cloud offloading techniques, whereas section~\ref{sec:applications} reviews some application models. Section~\ref{sec:thesis_position} concludes this chapter, and gives the position of this thesis, compared to research previously reviewed.
%
%
\section{Nodes organization}\label{sec:nodes_organization}
Guo et al.~\cite{GuoRG20}, gives a promising model based on a zone-based organization of edge nodes in the smart vehicles application. The authors show how zone-based nodes organization enables continuity of dynamic services and reduces the connection handovers. They prove it is possible to enlarge the coverage of edge servers to a bigger zone, but at the same time, the computing power and storage capacity of edge servers could be expanded. EC could be based on the geo-distributed workloads, and this zone-based organization could benefit the EC model in various ways. 

In their research~\cite{BaktirOE17}, Baktir et al. explored the capabilities of software-defined networks (SDN) from a programming standpoint. Their findings show that SDN can be used to simplify the management of the network in a cloud-like environment. Networking in such a complex environment is not an easy task to achieve. The authors show how SDN hides the complexity of the heterogeneous environment from the end-users. As such, SDNs represent a good candidate for networking tasks in complex, cloud-like environments. 

Sayed et al. in their work~\cite{El-SayedSPPGML18} show that EC systems will perform actions before connecting to the cloud and how they are easier to integrate with other wireless networks like mobile ad-hoc networks (MANETs), vehicular ad-hoc networks (VANETs), intelligent transport systems (ITSs) and the IoT to mitigate network-related and computational problems.

Content delivery networks (CDN) in centralized delivery models like CC have bad scalability, as Kurniawan et al.~\cite{inbookKurniawan} argue in their research. To overcome these centralized problems and bad scalability, the authors proposed a different solution, a decentralized solution. To achieve such tasks, authors were using a network of gateways equipped with some storage as well, for internet services at home~\cite{inbookKurniawan} forming even smaller DCs -- nano DCs. Authors present a possible usage for these nano DCs in some large scale applications with much less energy consumption than traditional DCs.

In their paper~\cite{CiobanuNPDMM19}, Ciobanu et al. introduce an interesting idea called \textit{drop computing}. The authors show the possibility for ad-hoc EC platform composition using a decentralized model over multilayered social crowd networks. This idea gives us the ability for collaborative computing that can be formed dynamically. The authors present an idea that we can form a computing group ad-hoc by employing the nearby devices in the mobile crowd, that is fully capable of quick and efficient access to resources, instead of sending requests to the cloud. Crowd nodes could also be an interesting idea for backup nodes, in case more computing power or storage is needed and there no more available resources to use. Forming platforms from crowd resources and ad-hoc, raises a few concerns: \textbf{(1)} crowd nodes availability, and \textbf{(2)} offered resources. 

Greenberg et al.~\cite{GreenbergHMP09} introduce the idea of MDCs as DCs that operate in proximity to a big population compared to nano DCs that serve a lot smaller population, for example, a single household. MDCs are an interesting model and area of rapid innovation and development, and because they are close to some population, they are minimizing the costs and the latency for end-users~\cite{, GreenbergHMP09}, Their minimum size is defined by the needs of the local population~\cite{GreenbergHMP09, AbbasZTS18}, as such, they are reducing traditional DCs fixed costs. The main feature that MDCs are rely on is agility. The authors describe agility as MDCs ability to dynamically grow and shrink resources to satisfy the resource demands and usage from the most optimal location~\cite{GreenbergHMP09}. In~\cite{ShaoLFJL19} Shao et al. present a possible MDCs structure serving only the local population, in the smart city use-case.
%
%
\section{Platform models}\label{sec:platform_models}
%
Kubernetes (k8s for short)~\cite{BurnsGOBW16} is a system originally developed by Google influenced by their orchestrator platform called Borg~\cite{VermaPKOTW15}. Various other companies joined in developing this system, and now it is de facto standard in the cloud environment for microservices and cloud-native applications. By design, Kubernetes is not intended to operate in a geo-distributed environment, because it operates on a single cluster~\cite{BurnsGOBW16, VermaPKOTW15, RossiCPN20}. As such it might not be best suited for EC and geo-distributed micro-clouds. Nonetheless, it is a super valuable tool in the CC because it enables health checking, restarting, and orchestration at scale. Another potential problem with Kubernetes is its relatively complicated deployment concept that might be too complicated for EC workloads. It is developed to connect microservices across the CC environment. It could be used as it is, a cloud-native orchestrator to run the master process for EC and micro-clouds and also cloud-native applications that will accept streams coming from micro-cloud applications. Kubernetes relies upon a lot to work properly. Existing technologies and ideas worth exploring, such as loosely coupling elements with labels and selectors, should not be ignored.

In their research, Rossi et al.~\cite{RossiCPN20} present a solution based on Kubernetes. Authors adapted Kubernetes for workloads that are geo-distributed and they had used reinforcement learning (RL) techniques, to learn a suitable scaling policy from past experience. There are potential downsides to this approach. The first might be that machine learning implementation could be potentially slow due to the required model training, but also we need to somehow describe what a good decision, and what a bad decision is, in order to enable some algorithm to learn this. This might be a problematic thing, especially in urgent situations. The second potential problem is that, even though Kubernetes is a promising solution and de-facto standard in the CC environment, as previously stated, it might not be the best proposal for EC and geo-distributed micro-cloud environment. Despite all these potential problems, researchers show great work in adapting Kubernetes architecture to work for geo-distributed workloads.

Ryden et al.~\cite{RydenOCW14} presents an interesting platform for distributed computing, that is more oriented towards user-based applications\label{sec:rayden}. Compared to other similar systems. their goal was not to develop a solution that will do resource management policy, on the contrary, their focus is more oriented to give flexibility to the users for application development. Users can develop their applications using exclusively Javascript (JS) programming language, with some embedded native code for a more efficient solution. The authors rely on a bunch of volunteer nodes to run all the tasks and applications, similar to work presented in~\cite{CiobanuNPDMM19}. The main difference between these two solutions is that Ryden et al. make a split on which nodes are storage nodes, and which nodes are used for calculation and processing tasks. Their application environment is protected from malicious code, using sandboxing techniques. This presents an interesting work to show how users can develop applications and run them in an EC environment.

In~\cite{LebrePSD17} L{\`{e}}bre et al. show an interesting solution based on extending and adopting the OpenStack system. OpenStack is a free and open standard cloud computing IaaS platform for CC use cases in both public and private clouds. The authors tried to manage both cloud and edge resources using a NoSQL database. Massively distributed multi-site IaaS, using OpenStack is a challenging task~\cite{LebrePSD17} to implement, because the communication between nodes of different sites can be subject to important network latencies~\cite{LebrePSD17}. On the other hand, if it could be done properly we would gain one major advantage that users of the IaaS solution can continue using the same familiar infrastructure for both cloud and edge/fog use-cases.

Based on the literature survey, the Ning et al. presents current open issues of EC platforms~\cite{NingLSY20}. In their work, authors focus on different aspects of EC systems, and they outline the importance of EC and CC tight collaboration. The CC needs to be unloaded and EC nodes could provide data pre-processing. On the other hand, EC needs massive storage and a strong computing capacity of CC. The authors illustrate the usage of edge computing platforms to build specific applications and conclude that with CC and EC integration, both sides will benefit.

In~\cite{abs-1802-10375} the de Guzm{\'{a}}n et al. present solution based on Kubernetes that use Kubernetes Deployment Manifests to reuse successful principles from Kubernetes by creating a virtual machine for each Pod using Linuxkit. Their solution is based on the immutable infrastructure pattern, and instead of containers, they use the virtual machines as the unit of deployment. Authors prove that the attack surface of their system is reduced since Linuxkit only installs the minimum OS dependencies to run containers. It represents interesting usage of LinuxKit to deploy OS dependencies and immutable infrastructure patterns, but VMs might be a bit problem for small devices, and ARM nodes as well as the complex flow of the Kubernetes application model. Nonetheless, it is an interesting extension of the Kubernetes framework and proves that LinuxKit can be used for immutable infrastructures with custom OS.

In~\cite{SamiM20} Sami et al. show an interesting platform for dynamic services distribution over Fog nodes using volunteer nodes. Their platform is tuned for container placement with relevance and efficiency on volunteering fog devices, near users with maximum time availability and shortest distance. They do this \textit{on the fly}  with improved QoS.

Besides academy efforts, the industry as well introduced a few interesting platforms and frameworks for EC. For example, Amazon introduced their framework Greengrass~\cite{kurniawan_2018} that can run on various hardware to do some processing. Amazon turns to the option that their framework is deeply connected to the rest of the AWS cloud ecosystem.  KubeEdge~\cite{KubeEdge} is a lightweight extension of the Kubernetes framework, to operate in an EC environment. The same as regular Kubernetes, all workloads are done in the domain of a single cluster which might not be the best solution for geo-distributed micro-clouds. Both Greengrass and KubeEdge are frameworks that are mainly used for user-based applications. On the other hand, there is General Electric with its Predix~\cite{GE_Predix} platform. Predix is a scalable platform used for industrial IoT applications.
%
%
\section{Task offloading}\label{sec:task_offloading}
%
As already mentioned in~\ref{sec:mobile_computing} EC nodes rely on the concept of data and computation offloading from the cloud closer to the ground \cite{KhuneP19}, while heavy computation remains in the cloud because of resource availability~\cite{NingLSY20}. 

Offloading is an effective strategy when using cloud services. Relying only on cloud services may be prone to introducing long latency, which some applications cannot tolerate. On the other hand, mobile devices and sensors do not have sufficient battery energy for task offloading~\cite{MaoZL16}. The computation performance may be compromised due to insufficient battery energy for task offloading, so these devices might send their data to nearby EC nodes.

In literature, there are few platforms proposing task offloading~\cite{ShiHPANZ14, KhuneP19, ChenHLLW15, LinLJL19, JiangCGZW19, MaoZL16} to the nearby edge layer. These offloading techniques are based on different parameters, options, and techniques to put tasks to different sets of nodes in such a way that it won't drain mobile devices and sensors battery. After the computation is done, this edge layer sends pre-processed data to the cloud for further analysis, storage, etc.

When using task offloading techniques, it is very important to have good QoS that users can rely on. In~\cite{SamiM20} authors used Evolutionary Memetic Algorithm (MA) to solve their multi-objective container placement optimization problem to achieve better QoS.

\new{One of the key challenges in the are of computation offloading is in the mismatch between how devices demand and access computing resources and how cloud providers offer them~\cite{ShiHPANZ14}. For example, it takes around 27 seconds to start single VM instance on the AWS, but the leasing time for the single VM instance is one hour. On the other hand, execution delay is stable in the CC, while in the EC is not due to the computational and transmission delay~\cite{WangZMHNW18}.}
%
%
\section{Application models}\label{sec:applications}
%
Sayed et al. in their work~\cite{El-SayedSPPGML18} describe that EC follows a decentralized architecture model and that data processing is at the edge of the network, thus it enables nodes to make autonomous decisions.  So the applications written for EC can perform actions locally before connecting to the cloud at all. This will have some benefits like reducing network overhead issues as well as the security and privacy issues. 

As already mentioned on page~\pageref{sec:rayden}, Ryden et al.~\cite{RydenOCW14} presents an interesting user-oriented platform for distributed computing called Nebula. In this section, their research is going to be dissected, but from a different angle. Nebula allows users to develop their applications using JS exclusively, due to the usage of Google Chrome Web browser-based Native Client (NaCl) sandbox~\cite{YeeSDCMOONF10} that can run JS code only. Restriction on a single language might be a problem for some users and use-cases even though JS is a popular language at the moment. On the other hand, virtual machines tend to be too resource-demanding packing stuff that might not be needed, so a solution using containers or unikernels might provide better resource utilization and pack more services per node than virtual machines.

In~\cite{SatyanarayananBCD09} Satyanarayanan et al. represent an interesting view on cloudlets as a \say{data center in a box.}. They give an example that cloudlets should support a wide range of users, with minimal constraints on their software. They put emphasis on transient VM technology. The emphasis on transient VMs is because cloudlet infrastructure is restored to its pristine software state after each use, without manual intervention. At the time when they conducted their research, containers might not have been working solution or it might have been hard to use them. By modern standards, containers may even fit better, and pack more user software on the same hardware. This may be the case for the unikernels, once they reach a wider adoption rate and stable products.

Various Kubernetes variants like~\cite{KubeEdge, RossiCPN20}, give users the possibility to run different applications like web servers and databases even on smaller devices creating green DC~\cite{ArocaG12}.

Satyanarayanan et al.~\cite{SatyanarayananK19} propose the concept of edge-native applications that will separate space into 3 layers or tiers. Tier \textbf{(1)} represents various mobile, IoT devices autonomous vehicles, etc, and these devices produce a lot of data. Tier \textbf{(2)} represents applications running in cloudlets or other EC models, that will be able to do some pre-processing, or data filtering before it goes further. Finally, tier \textbf{(3)} represents classic cloud applications that will accept pre-processed and filtered data from the previous tier, do more processing, react on some values, or store for future use. This idea represents an interesting concept and gives wide space for users and application development.

In~\cite{inproceedingsBeck} Beck et al. argue that applications should use message bus, streams, or topics because most mobile or edge applications are expected to be event-driven. The message bus system is an interesting proposition because the virtualized applications can subscribe to message streams, i.e., topics, and act only when data arrive. Applications might not be alive the whole time. And if for some reason mobile edge applications cannot reach a close EC server, it can always send data to the cloud. So cloud applications should be changed so slightly, just to cover this edge case.

In~\cite{JararwehDAAAB16}, Jararweh et al. show how integration between EC with CC principles will create more complex services and applications at the edge of the network opening new possibilities for applications to reduce the load on the centralized cloud model but also avoid bottlenecks and single points of failure.
%
%
\section{Thesis position}\label{sec:thesis_position}
%
In the previous sections, different aspects of EC and integration with the CC, influential research, interesting concepts, and implementations were described.

The focus of this thesis is a little bit different from the aforementioned work. This thesis wants to make the connection between CC and EC stronger represented as a system that can descriptively and dynamically organize geo-distributed nodes that already exist over an arbitrary vast area into one coherent system. This approach is not fully addressed in other solutions. 

This thesis is influenced by the organization of CC and their big DCs but adapted for a different environment such as EC and micro-clouds, influenced by the work described in previous sections. 

Adaptations that are required for such tasks must be followed by a clear Separation of concerns (SoC) model and intuitive applications model so that users can fully use new-formed infrastructure properly. 

All these will make it possible to push the whole solution more towards EC as a service and micro-cloud model that can help CC with latency issues with new-age applications.
%
%